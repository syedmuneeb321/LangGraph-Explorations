{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNozULnz+F3Cmfg+DruwBY/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedmuneeb321/LangGraph-Explorations/blob/main/Getting_Started_With_LangGraph/agent_with_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhJ-gOM9vG4F"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langsmith langchain_google_genai tavily-python langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "\n",
        "gemini_api_key = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "G0bB8BvAvffd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    api_key=gemini_api_key\n",
        ")\n"
      ],
      "metadata": {
        "id": "2BafSPeSvux5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph,START,END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_community.tools import TavilySearchResults\n",
        "from langgraph.checkpoint.memory import MemorySaver"
      ],
      "metadata": {
        "id": "y4JHVmbOwC_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make tool and bind llm\n",
        "tool = TavilySearchResults(max_results=2)\n",
        "tool_with_llm = llm.bind_tools([tool])"
      ],
      "metadata": {
        "id": "y4gzkmREyV4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# state making\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list,add_messages]\n"
      ],
      "metadata": {
        "id": "h1yKYK0cxmkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make chat bot\n",
        "def chat_bot(state:State)->State:\n",
        "  response = tool_with_llm.invoke(state[\"messages\"])\n",
        "  return {\"messages\":[response]}"
      ],
      "metadata": {
        "id": "VEurdWcwx4tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a tool call node\n",
        "from langgraph.prebuilt import ToolNode,tools_condition\n",
        "\n",
        "tool_call_node = ToolNode([tool])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "W7bcwyrRy7WU",
        "outputId": "163c6b9b-2f3b-4d78-b723-422f51026134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langgraph'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a6e11773b4ee>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make a tool call node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprebuilt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToolNode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtools_condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtool_call_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToolNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# add node\n",
        "graph_builder.add_node(\"chat_bot\",chat_bot)\n",
        "graph_builder.add_node(\"tools\",tool_call_node)\n",
        "\n",
        "# logic\n",
        "\n",
        "graph_builder.add_edge(START,\"chat_bot\")\n",
        "graph_builder.add_conditional_edges(\"chat_bot\",tools_condition)\n",
        "graph_builder.add_edge(\"tools\",\"chat_bot\")\n",
        "\n",
        "\n",
        "# create a memory instance and give compoile graph check pointer parameter\n",
        "memory = MemorySaver()\n",
        "app = graph_builder.compile(checkpointer=memory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "MtGvmyv8zgod",
        "outputId": "5d45c0ce-3983-4c63-e2b6-cc72fde211ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'StateGraph' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6e81333274ec>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgraph_builder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# add node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'StateGraph' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "fqVcHdMp03Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input = {\"messages\":[{\"role\":\"user\",\"content\":\"what is \"}]}\n",
        "\n",
        "thread_config = {\"configurable\":{\"thread_id\":\"1\"}}\n",
        "\n",
        "for event in app.stream(input=input,config=thread_config,stream_mode=\"values\"):\n",
        "  # print(event)\n",
        "  event['messages'][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmykj-QQ07o6",
        "outputId": "a1f881c8-35f1-4293-f727-ff8baa141c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "what is langchain\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "LangChain is a framework for developing applications powered by large language models (LLMs). It allows you to connect LLMs to various data sources and tools, enabling them to perform complex tasks like:\n",
            "\n",
            "* **Question Answering:** Retrieve information from databases, websites, or documents and answer questions based on the retrieved data.\n",
            "* **Summarization:** Summarize long documents or articles.\n",
            "* **Text Generation:** Generate creative content, write different kinds of text formats (emails, articles, code), and translate languages.\n",
            "* **Chatbots:** Build conversational agents that can interact with users in a natural way.\n",
            "\n",
            "**Key Features of LangChain:**\n",
            "\n",
            "* **Modular Design:** LangChain is built around the concept of chains, which are sequences of components that work together to achieve a specific goal. This modularity allows for easy customization and extension.\n",
            "* **Data Connectivity:** LangChain provides various tools for connecting LLMs to different data sources, including databases, APIs, and file systems.\n",
            "* **Tool Integration:**  It allows you to integrate LLMs with external tools and services, such as Wolfram Alpha, Google Search, and Python libraries.\n",
            "* **Chain Composition:** You can combine multiple chains to create more complex applications that involve multiple steps or data sources.\n",
            "\n",
            "**Benefits of Using LangChain:**\n",
            "\n",
            "* **Faster Development:** LangChain simplifies the process of building LLM-powered applications by providing pre-built components and tools.\n",
            "* **Improved Performance:** LangChain optimizes the interaction between LLMs and data sources, resulting in faster and more efficient applications.\n",
            "* **Enhanced Capabilities:** By combining LLMs with external tools and data sources, LangChain unlocks new capabilities and possibilities.\n",
            "\n",
            "**Example:**\n",
            "\n",
            "Imagine you want to build a chatbot that can answer questions about a specific topic. Using LangChain, you could:\n",
            "\n",
            "1. **Connect the LLM to a database of relevant information.**\n",
            "2. **Use a chain to process user queries, retrieve relevant information from the database, and provide answers.**\n",
            "3. **Integrate a summarization tool to provide concise and understandable answers.**\n",
            "\n",
            "LangChain empowers developers to create powerful and innovative applications that leverage the capabilities of LLMs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot = app.get_state(config=thread_config)\n",
        "dir(snapshot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFXS31dC2Vcj",
        "outputId": "8a3cce9b-e584-4b49-b5bb-183f8968e7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__getnewargs__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__match_args__',\n",
              " '__module__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__orig_bases__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__rmul__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '_asdict',\n",
              " '_field_defaults',\n",
              " '_fields',\n",
              " '_make',\n",
              " '_replace',\n",
              " 'config',\n",
              " 'count',\n",
              " 'created_at',\n",
              " 'index',\n",
              " 'metadata',\n",
              " 'next',\n",
              " 'parent_config',\n",
              " 'tasks',\n",
              " 'values']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlJo4eGw38x6",
        "outputId": "8c6f8f82-b34d-4768-8da8-87e9d602faed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='what is langchain', additional_kwargs={}, response_metadata={}, id='963bcd9b-a5b1-42a8-a2bd-9320a9d26805'),\n",
              "  AIMessage(content=\"I can't provide information about LangChain using the available tools. I am only able to use the `default_api` which is limited in functionality. \\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-9e9a6f1f-19b1-4f49-80a7-3ebe0e008e22-0', usage_metadata={'input_tokens': 78, 'output_tokens': 32, 'total_tokens': 110, 'input_token_details': {'cache_read': 0}}),\n",
              "  HumanMessage(content='what is langchain', additional_kwargs={}, response_metadata={}, id='90303f2a-46b9-4af9-8769-3e5ff8a67fef'),\n",
              "  AIMessage(content='LangChain is a framework for developing applications powered by large language models (LLMs). It allows you to connect LLMs to various data sources and tools, enabling them to perform complex tasks like:\\n\\n* **Question Answering:** Retrieve information from databases, websites, or documents and answer questions based on the retrieved data.\\n* **Summarization:** Summarize long documents or articles.\\n* **Text Generation:** Generate creative content, write different kinds of text formats (emails, articles, code), and translate languages.\\n* **Chatbots:** Build conversational agents that can interact with users in a natural way.\\n\\n**Key Features of LangChain:**\\n\\n* **Modular Design:** LangChain is built around the concept of chains, which are sequences of components that work together to achieve a specific goal. This modularity allows for easy customization and extension.\\n* **Data Connectivity:** LangChain provides various tools for connecting LLMs to different data sources, including databases, APIs, and file systems.\\n* **Tool Integration:**  It allows you to integrate LLMs with external tools and services, such as Wolfram Alpha, Google Search, and Python libraries.\\n* **Chain Composition:** You can combine multiple chains to create more complex applications that involve multiple steps or data sources.\\n\\n**Benefits of Using LangChain:**\\n\\n* **Faster Development:** LangChain simplifies the process of building LLM-powered applications by providing pre-built components and tools.\\n* **Improved Performance:** LangChain optimizes the interaction between LLMs and data sources, resulting in faster and more efficient applications.\\n* **Enhanced Capabilities:** By combining LLMs with external tools and data sources, LangChain unlocks new capabilities and possibilities.\\n\\n**Example:**\\n\\nImagine you want to build a chatbot that can answer questions about a specific topic. Using LangChain, you could:\\n\\n1. **Connect the LLM to a database of relevant information.**\\n2. **Use a chain to process user queries, retrieve relevant information from the database, and provide answers.**\\n3. **Integrate a summarization tool to provide concise and understandable answers.**\\n\\nLangChain empowers developers to create powerful and innovative applications that leverage the capabilities of LLMs.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-8ae7237a-b5df-4cd9-9a8c-1cd9325b3cc0-0', usage_metadata={'input_tokens': 118, 'output_tokens': 444, 'total_tokens': 562, 'input_token_details': {'cache_read': 0}})]}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y773327P3xoU",
        "outputId": "3554dbdd-eff7-4dd3-af08-e248908d2859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '1',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1ef9a9d4-f479-6759-8004-c22dd5589704'}}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot.metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHvbIlXh4So0",
        "outputId": "ece4f063-08ea-41a1-ce94-c95f446cef33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'loop',\n",
              " 'writes': {'chat_bot': {'messages': [AIMessage(content='LangChain is a framework for developing applications powered by large language models (LLMs). It allows you to connect LLMs to various data sources and tools, enabling them to perform complex tasks like:\\n\\n* **Question Answering:** Retrieve information from databases, websites, or documents and answer questions based on the retrieved data.\\n* **Summarization:** Summarize long documents or articles.\\n* **Text Generation:** Generate creative content, write different kinds of text formats (emails, articles, code), and translate languages.\\n* **Chatbots:** Build conversational agents that can interact with users in a natural way.\\n\\n**Key Features of LangChain:**\\n\\n* **Modular Design:** LangChain is built around the concept of chains, which are sequences of components that work together to achieve a specific goal. This modularity allows for easy customization and extension.\\n* **Data Connectivity:** LangChain provides various tools for connecting LLMs to different data sources, including databases, APIs, and file systems.\\n* **Tool Integration:**  It allows you to integrate LLMs with external tools and services, such as Wolfram Alpha, Google Search, and Python libraries.\\n* **Chain Composition:** You can combine multiple chains to create more complex applications that involve multiple steps or data sources.\\n\\n**Benefits of Using LangChain:**\\n\\n* **Faster Development:** LangChain simplifies the process of building LLM-powered applications by providing pre-built components and tools.\\n* **Improved Performance:** LangChain optimizes the interaction between LLMs and data sources, resulting in faster and more efficient applications.\\n* **Enhanced Capabilities:** By combining LLMs with external tools and data sources, LangChain unlocks new capabilities and possibilities.\\n\\n**Example:**\\n\\nImagine you want to build a chatbot that can answer questions about a specific topic. Using LangChain, you could:\\n\\n1. **Connect the LLM to a database of relevant information.**\\n2. **Use a chain to process user queries, retrieve relevant information from the database, and provide answers.**\\n3. **Integrate a summarization tool to provide concise and understandable answers.**\\n\\nLangChain empowers developers to create powerful and innovative applications that leverage the capabilities of LLMs.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-8ae7237a-b5df-4cd9-9a8c-1cd9325b3cc0-0', usage_metadata={'input_tokens': 118, 'output_tokens': 444, 'total_tokens': 562, 'input_token_details': {'cache_read': 0}})]}},\n",
              " 'step': 4,\n",
              " 'parents': {}}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snapshot.next"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oieV9fTP4XEE",
        "outputId": "a44132f4-adf7-4ae1-8cba-1c740a19710e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(app)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdqaZlf14iVs",
        "outputId": "21e81e37-1c08-40fa-c934-737b5c3cb33e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['InputType',\n",
              " 'OutputType',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__or__',\n",
              " '__orig_bases__',\n",
              " '__parameters__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__ror__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abatch_with_config',\n",
              " '_abc_impl',\n",
              " '_acall_with_config',\n",
              " '_aprepare_state_snapshot',\n",
              " '_atransform_stream_with_config',\n",
              " '_batch_with_config',\n",
              " '_call_with_config',\n",
              " '_defaults',\n",
              " '_is_protocol',\n",
              " '_prepare_state_snapshot',\n",
              " '_transform_stream_with_config',\n",
              " 'abatch',\n",
              " 'abatch_as_completed',\n",
              " 'aget_graph',\n",
              " 'aget_state',\n",
              " 'aget_state_history',\n",
              " 'aget_subgraphs',\n",
              " 'ainvoke',\n",
              " 'as_tool',\n",
              " 'assign',\n",
              " 'astream',\n",
              " 'astream_events',\n",
              " 'astream_log',\n",
              " 'atransform',\n",
              " 'attach_branch',\n",
              " 'attach_edge',\n",
              " 'attach_node',\n",
              " 'aupdate_state',\n",
              " 'batch',\n",
              " 'batch_as_completed',\n",
              " 'bind',\n",
              " 'builder',\n",
              " 'channels',\n",
              " 'checkpointer',\n",
              " 'config',\n",
              " 'config_schema',\n",
              " 'config_specs',\n",
              " 'config_type',\n",
              " 'copy',\n",
              " 'debug',\n",
              " 'get_config_jsonschema',\n",
              " 'get_graph',\n",
              " 'get_input_jsonschema',\n",
              " 'get_input_schema',\n",
              " 'get_name',\n",
              " 'get_output_jsonschema',\n",
              " 'get_output_schema',\n",
              " 'get_prompts',\n",
              " 'get_state',\n",
              " 'get_state_history',\n",
              " 'get_subgraphs',\n",
              " 'input_channels',\n",
              " 'input_schema',\n",
              " 'interrupt_after_nodes',\n",
              " 'interrupt_before_nodes',\n",
              " 'invoke',\n",
              " 'map',\n",
              " 'name',\n",
              " 'nodes',\n",
              " 'output_channels',\n",
              " 'output_schema',\n",
              " 'pick',\n",
              " 'pipe',\n",
              " 'retry_policy',\n",
              " 'step_timeout',\n",
              " 'store',\n",
              " 'stream',\n",
              " 'stream_channels',\n",
              " 'stream_channels_asis',\n",
              " 'stream_channels_list',\n",
              " 'stream_mode',\n",
              " 'transform',\n",
              " 'update_state',\n",
              " 'validate',\n",
              " 'with_alisteners',\n",
              " 'with_config',\n",
              " 'with_fallbacks',\n",
              " 'with_listeners',\n",
              " 'with_retry',\n",
              " 'with_types']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(graph_builder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrZ-HHtC43bz",
        "outputId": "bcb9040d-c73d-4206-c7fe-3e557cc0e00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_add_schema',\n",
              " '_all_edges',\n",
              " 'add_conditional_edges',\n",
              " 'add_edge',\n",
              " 'add_node',\n",
              " 'branches',\n",
              " 'channels',\n",
              " 'compile',\n",
              " 'compiled',\n",
              " 'config_schema',\n",
              " 'edges',\n",
              " 'input',\n",
              " 'managed',\n",
              " 'nodes',\n",
              " 'output',\n",
              " 'schema',\n",
              " 'schemas',\n",
              " 'set_conditional_entry_point',\n",
              " 'set_entry_point',\n",
              " 'set_finish_point',\n",
              " 'support_multiple_edges',\n",
              " 'validate',\n",
              " 'waiting_edges']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8YKGoEl6DUO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}